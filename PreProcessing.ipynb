{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "from sklearn.model_selection import train_test_split as sk_train_test_split\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.preprocessing import StandardScaler\n", "import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def null_value_analysis(df):\n", "    # Drop null values\n", "    df = df.dropna()\n", "    return df"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def duplicate_value_analysis(df):\n", "    # Drop duplicate values\n", "    df = df.drop_duplicates()\n", "    return df"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def outlier_analysis(df):\n", "     # Initialize masks\n", "    mask = np.ones(len(df), dtype=bool)\n\n", "    # Iterate over each numerical column to update the mask\n", "    for col in df.select_dtypes(include=[np.number]).columns:\n", "        if col != 'TARGET_5Yrs' and col != 'Id':  # Skip the target and id column\n", "            z_scores = np.abs((df[col] - df[col].mean()) / df[col].std())\n", "            mask = mask & (z_scores < 3)\n\n", "    # Calculate the number of outliers\n", "    outliers_target_1 = len(df[(~mask) & (df['TARGET_5Yrs'] == 1)])\n", "    outliers_target_0 = len(df[(~mask) & (df['TARGET_5Yrs'] == 0)])\n\n", "    # Calculate the total number of instances in each class\n", "    total_target_1 = len(df[df['TARGET_5Yrs'] == 1])\n", "    total_target_0 = len(df[df['TARGET_5Yrs'] == 0])\n\n", "    # Calculate the percentage of outliers in each class\n", "    percent_outliers_target_1 = (outliers_target_1 / total_target_1) * 100 if total_target_1 > 0 else 0\n", "    percent_outliers_target_0 = (outliers_target_0 / total_target_0) * 100 if total_target_0 > 0 else 0\n\n", "    # Print the number of outliers and their percentages\n", "    print(f\"Number of outliers when TARGET_5Yrs is 1: {outliers_target_1} ({percent_outliers_target_1:.2f}%)\")\n", "    print(f\"Number of outliers when TARGET_5Yrs is 0: {outliers_target_0} ({percent_outliers_target_0:.2f}%)\")\n\n", "    # Return the DataFrame with rows removed where the mask is False\n", "    return df[mask]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def feature_engineering(df):\n", "    # Add or modify features if necessary\n", "    # Example: Creating a new feature based on existing ones\n", "    df['Points_Per_Minute'] = (df['PTS'] / df['MIN']).round(3)\n", "    df['Field_Goal_Efficiency'] = (df['FGM'] / df['FGA']).round(3)\n", "    df['Points_Per_Game_Played'] = (df['PTS'] / df['GP']).round(3)\n", "    df['Total_Rebounds'] = (df['OREB'] + df['DREB']).round(3)\n", "    df['DREB_Per_Game'] = (df['DREB'] / df['GP']).round(3)\n", "    df['STL_Per_Game'] = (df['STL'] / df['GP']).round(3)\n", "    df['BLK_Per_Game'] = (df['BLK'] / df['GP']).round(3)\n", "    df['TOV_Per_Game'] = (df['TOV'] / df['GP']).round(3)\n", "    df['Points_Per_FGA'] = (df['PTS'] / df['FGA']).round(3)\n", "    df['Points_Per_REB'] = (df['PTS'] / df['REB']).round(3)\n", "    df['TOV_Per_Minute'] = (df['TOV'] / df['MIN']).round(3)\n", "    df['TOV_Per_Game'] = (df['TOV'] / df['GP']).round(3)\n", "    df['FGM_Missed_Per_Game'] = ((df['FGA'] - df['FGM']) / df['GP']).round(3)\n", "    df['FT_Missed_Per_Game'] = ((df['FTA'] - df['FTM']) / df['GP']).round(3)\n", "    df['FG_Missed_Percentage'] = (1 - df['FG%']).round(3)\n\n", "    # More complicated feature engineering stats\n", "    df['Offensive_Rating'] = ((df['PTS'] / df['MIN']) * 100).round(3)\n", "    df['Defensive_Rating'] = ((df['DREB'] / df['MIN']) * 100).round(3)\n", "    df['Usage_Rate'] = (((df['FGA'] + df['TOV'] + (0.44 * df['FTA'])) * (df['GP'] / 5)) / df['MIN']).round(3) \n", "    df['True_Shooting_Percentage'] = (df['PTS'] / (2 * (df['FGA'] + (0.44 * df['FTA'])))).round(3)\n", "    df['Effective_Field_Goal_Percentage'] = (((df['FGM'] + (0.5 * df['3P Made'])) / df['FGA'])).round(3)\n", "    df['Turnover_Percentage'] = ((df['TOV'] / (df['FGA'] + (0.44 * df['FTA']) + df['TOV'])) * 100).round(3)\n", "    df['Offensive_Rebound_Percentage'] = ((df['OREB'] / (df['OREB'] + df['DREB'])) * 100).round(3)\n", "    df['Defensive_Rebound_Percentage'] = ((df['DREB'] / (df['DREB'] + df['OREB'])) * 100).round(3)\n\n", "    # Non linear features\n", "    df['PTS_Cubed'] = df['PTS'] ** 3\n", "    df['Usage_Rate_Power4'] = df['Usage_Rate'] ** 4 \n", "    df['PTS_MIN_Poly'] = (df['PTS'] ** 2) * (df['MIN'] ** 2)\n", "    df['FT_FGA_Poly'] = (df['FTM'] ** 2) * (df['FGA'] ** 3)\n", "    df['Efficiency_Usage_Interaction'] = (df['True_Shooting_Percentage'] ** 2) * (df['Usage_Rate'] ** 3)\n", "    df['Defensive_Complex'] = (df['Defensive_Rating'] ** 2) * (df['STL_Per_Game'] + df['BLK_Per_Game']) ** 2\n", "    df['PTS_FG%_Fractional'] = (df['PTS'] ** (2/3)) * (df['FG%'] ** (1/3))\n", "    df['Usage_TOV_Fractional'] = (df['Usage_Rate'] ** (1/2)) / (df['TOV_Per_Minute'] ** (1/4))\n", "    df['Log_Exp_Cross'] = np.log(df['PTS'] + 1) * np.exp(df['MIN'] / 100)\n", "    df['Sin_MIN'] = np.sin(df['MIN'])\n", "    df['Cos_MIN'] = np.cos(df['MIN'])\n\n", "    # Scaling\n", "    scaler = StandardScaler()  # Or MinMaxScaler()\n", "    features = ['MIN', 'PTS', 'FGM', 'FGA', '3PA', 'FTA', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV']  # List all features needing scaling\n", "    df[features] = scaler.fit_transform(df[features])\n\n", "    # Drop columns that have a low feature importance\n", "    columns_to_drop = [\n", "    'FG_Missed_Percentage', 'FG%', 'Offensive_Rebound_Percentage', 'PTS_MIN_Poly',\n", "    'Points_Per_Minute', 'FT_FGA_Poly', 'Defensive_Rebound_Percentage', '3PA',\n", "    'TOV_Per_Minute', 'FTM', 'MIN', 'Log_Exp_Cross', 'AST', 'Points_Per_Game_Played',\n", "    'FGM_Missed_Per_Game', 'DREB_Per_Game', 'TOV_Per_Game', 'REB', 'FT_Missed_Per_Game',\n", "    'FTA', 'Total_Rebounds', 'BLK_Per_Game', 'PTS', 'OREB', 'STL_Per_Game', 'DREB',\n", "    '3P Made', 'FGM', 'BLK', 'FGA', 'PTS_Cubed', 'TOV', 'STL']\n", "    df = df.drop(columns=columns_to_drop)\n\n", "    # Drop the 'Id' column\n", "    df = df.drop(columns=['Id'])\n", "    df.to_csv('new_data.csv', index=False)\n", "    return df"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def determine_feature_importance(df):\n", "    # Determine feature importance using a model\n", "    x = df.drop(columns=['TARGET_5Yrs'])\n", "    y = df['TARGET_5Yrs']\n", "    model = RandomForestClassifier(class_weight = \"balanced\")\n", "    model.fit(x, y)\n", "    importances = model.feature_importances_\n", "    feature_importance = pd.Series(importances, index=x.columns)\n", "     \n", "    return feature_importance"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def perform_train_test_split(df):\n", "    # Print the number of entries with the target value as 1 and 0\\\n", "    print(\"Number of entries with target value as 1: \", len(df[df['TARGET_5Yrs'] == 1]))\n", "    print(\"Number of entries with target value as 0: \", len(df[df['TARGET_5Yrs'] == 0]))\n\n", "    # Separate the data based on the target value\n", "    df_class_1 = df[df['TARGET_5Yrs'] == 1]\n", "    df_class_0 = df[df['TARGET_5Yrs'] == 0]\n\n", "    # Split each class separately\n", "    x_class_1 = df_class_1.drop(columns=['TARGET_5Yrs'])\n", "    y_class_1 = df_class_1['TARGET_5Yrs']\n", "    x_class_0 = df_class_0.drop(columns=['TARGET_5Yrs'])\n", "    y_class_0 = df_class_0['TARGET_5Yrs']\n", "    x_train_1, x_test_1, y_train_1, y_test_1 = sk_train_test_split(x_class_1, y_class_1, test_size=0.1)\n", "    x_train_0, x_test_0, y_train_0, y_test_0 = sk_train_test_split(x_class_0, y_class_0, test_size=0.1)\n\n", "    # Combine the splits back together\n", "    x_train = pd.concat([x_train_1, x_train_0])\n", "    x_test = pd.concat([x_test_1, x_test_0])\n", "    y_train = pd.concat([y_train_1, y_train_0])\n", "    y_test = pd.concat([y_test_1, y_test_0])\n\n", "    # Print the number of entries in each class in the training and test sets\n", "    print(\"Training set - Number of entries with target value as 1: \", sum(y_train == 1))\n", "    print(\"Training set - Number of entries with target value as 0: \", sum(y_train == 0))\n", "    print(\"Test set - Number of entries with target value as 1: \", sum(y_test == 1))\n", "    print(\"Test set - Number of entries with target value as 0: \", sum(y_test == 0))\n", "    \n", "    return x_train, x_test, y_train, y_test"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}