{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import PreProcessing as preprocess \n", "import Modelling as modelling \n", "from ModelEvaluation import ModelEvaluation\n", "import numpy as np\n", "import pandas as pd\n", "import pickle "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main():\n", "    analyse_train_data()\n", "    analyse_test_data() "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def analyse_test_data():\n", "    # Take Test Data and Provide TARGET_5Yrs Predictions and Confidence Scores\n", "    test_data_original = pd.read_csv('nba_test.csv')\n", "    test_data_copy = test_data_original.copy()\n", "    \n", "    # Add the extra features to the test data\n", "    test_data_copy = preprocess.feature_engineering(test_data_copy)\n", "    \n", "    # Load the pre-trained Random Forest Model\n", "    rf_model = load_model('random_forest_model.pkl')\n", "    \n", "    # Make predictions\n", "    predictions = rf_model.predict(test_data_copy)\n", "    prediction_probabilities = rf_model.predict_proba(test_data_copy)[:, 1]  # Probability of class 1\n\n", "    # Add predictions to the test data\n", "    test_data_original['TARGET_5Yrs'] = predictions\n", "    test_data_original['Prediction_Probability'] = prediction_probabilities\n\n", "    # Save the result to a new CSV file\n", "    test_data_original.to_csv('nba_test_with_predictions.csv', index=False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def analyse_train_data():\n", "    train_data = pd.read_csv('nba_train.csv')\n", "    # STEP 1: PRE PROCESSING\n", "    # Training Data\n", "    print(\"--------------------------------------------------\")\n", "    print(\"Data Pre-processing Started...\")\n", "    train_data = preprocess.null_value_analysis(train_data)\n", "    train_data = preprocess.duplicate_value_analysis(train_data)\n", "    train_data = preprocess.outlier_analysis(train_data)\n", "    train_data = preprocess.feature_engineering(train_data)\n", "    feature_importance = preprocess.determine_feature_importance(train_data)\n", "    sorted_feature_importance = feature_importance.sort_values(ascending=False)\n", "    print(\"Feature Importances:\\n\", sorted_feature_importance)\n\n", "    # Splitting the training data into training and testing sets\n", "    x_train, x_test, y_train, y_test = preprocess.perform_train_test_split(train_data)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    print(\"Data Pre-processing Completed.\")\n", "    print(\"--------------------------------------------------\")\n", "    \n", "    # STEP 2: MODELLING\n", "    print(\"--------------------------------------------------\")\n", "    print(\"Modelling Started...\")\n", "    model_instance = modelling.Modelling(feature_importances = feature_importance)\n\n", "    # Define hyperparameters for each model\n", "    knn_params = {'n_neighbors': [2, 3, 5, 7, 10]}\n", "    dt_params = {'criterion': ['gini', 'entropy', 'log_loss'], 'max_depth': [None, 2, 4, 8, 10], 'min_samples_split': [2, 5], 'min_samples_leaf': [1, 2, 4]}\n", "    \n", "    rf_params = {\n", "        #'n_estimators': [50, 100, 200, 400], Commented out for faster execution but n = 100 has been determined as most optimal\n", "        'n_estimators': [100],\n", "        'max_depth': [None, 5,],\n", "        'min_samples_split': [2, 3],\n", "        'min_samples_leaf': [1, 2],\n", "        'criterion': ['gini', 'entropy', 'log_loss']\n", "    }\n\n", "    # Train and evaluate KNN\n", "    print(\"Beginning KNN Model Training and Evaluation...\")\n", "    knn_model = model_instance.train_model(x_train, y_train, 'knn', param_grid=knn_params)\n", "    knn_accuracy = model_instance.evaluate_model(knn_model, x_test, y_test)\n", "    print(\"KNN Model Accuracy On Testing Split (Overall, When 5yrs=1, When 5yrs=0):\", knn_accuracy)\n", "    knn_accuracy_train = model_instance.evaluate_model(knn_model, x_train, y_train)\n", "    print(\"KNN Model Accuracy On Training Split (Overall, When 5yrs=1, When 5yrs=0):\", knn_accuracy_train)\n", "    print(\"--------------------------------------------------\")\n\n", "    # Train and evaluate Decision Tree\n", "    print(\"Beginning Decision Tree Model Training and Evaluation...\")\n", "    dt_model = model_instance.train_model(x_train, y_train, 'decision_tree', param_grid=dt_params)\n", "    dt_accuracy = model_instance.evaluate_model(dt_model, x_test, y_test)\n", "    print(\"Decision Tree Model Accuracy On Testing Split (Overall, When 5yrs=1, When 5yrs=0):\", dt_accuracy)\n", "    dt_accuracy_train = model_instance.evaluate_model(dt_model, x_train, y_train)\n", "    print(\"Decision Tree Model Accuracy On Training Split (Overall, When 5yrs=1, When 5yrs=0):\", dt_accuracy_train)\n", "    print(\"--------------------------------------------------\")\n\n", "    # Train and evaluate Random Forest\n", "    print(\"Beginning Random Forest Model Training and Evaluation...\")\n", "    rf_model = model_instance.train_model(x_train, y_train, 'random_forest', param_grid=rf_params)\n", "    rf_accuracy = model_instance.evaluate_model(rf_model, x_test, y_test)\n", "    print(\"Random Forest Model Accuracy On Testing Split (Overall, When 5yrs=1, When 5yrs=0):\", rf_accuracy)\n", "    rf_accuracy_train = model_instance.evaluate_model(rf_model, x_train, y_train)\n", "    print(\"Random Forest Model Accuracy On Training Split (Overall, When 5yrs=1, When 5yrs=0):\", rf_accuracy_train)\n", "    print(\"--------------------------------------------------\")\n\n", "    # Perform KMeans clustering on the entire dataset\n", "    print (\"Performing KMeans Clustering...\")\n", "    kmeans_params = {'n_clusters': [2, 3, 4]}\n", "    kmeans_model, cluster_labels = model_instance.perform_clustering(train_data, 'kmeans', param_grid=kmeans_params)\n", "    print(\"KMeans Cluster Labels:\", cluster_labels)\n", "    print(\"KMeans Cluster Centers:\", kmeans_model.cluster_centers_)\n", "    print(\"--------------------------------------------------\")\n", "    \n", "    # Print chosen hyperparameters for each model\n", "    print(\"Best Hyperparameters:\")\n", "    print(\"KNN:\", model_instance.best_params['knn'])\n", "    print(\"Decision Tree:\", model_instance.best_params['decision_tree'])\n", "    print(\"Random Forest:\", model_instance.best_params['random_forest'])\n", "    print(\"K Means:\", model_instance.best_params['kmeans'])\n", "    print(\"Modelling Completed.\")\n", "    print(\"--------------------------------------------------\")\n\n", "    # STEP 4: MODEL EVALUATION\n", "    eval_instance = ModelEvaluation()\n", "    \n", "    # Evaluate KNN\n", "    knn_auc = eval_instance.evaluate_roc(knn_model, x_test, y_test, 'KNN')\n", "    print(\"KNN Model AUC:\", knn_auc)\n", "    \n", "    # Evaluate Decision Tree\n", "    dt_auc = eval_instance.evaluate_roc(dt_model, x_test, y_test, 'Decision Tree')\n", "    print(\"Decision Tree Model AUC:\", dt_auc)\n", "    \n", "    # Evaluate Random Forest\n", "    rf_auc = eval_instance.evaluate_roc(rf_model, x_test, y_test, 'Random Forest')\n", "    print(\"Random Forest Model AUC:\", rf_auc)\n", "    \n", "    # Plot ROC Curves\n", "    eval_instance.plot_roc_curve()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # Saving the chosen model (Random Forest) to a file\n", "    save_model(rf_model, 'random_forest_model.pkl')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_model(filename):\n", "    try:\n", "        with open(filename, 'rb') as file:\n", "            model = pickle.load(file)\n", "        print(f\"Model loaded from {filename}\")\n", "        return model\n", "    except FileNotFoundError:\n", "        print(f\"File {filename} not found.\")\n", "        return None\n", "def save_model(model, filename):\n", "    with open(filename, 'wb') as file:\n", "        pickle.dump(model, file)\n", "    print(f\"Model saved to {filename}\")\n", "    \n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}